#!/usr/bin/env python3
import numpy as np
import transformation
import mapping
import cv2
import skimage.morphology
import skfmm
import time
import numpy.ma as npmask
import lcmutils
from lcm_types.pose_t import pose_t
from lcm_types.pointcloud_t import pointcloud_t
from lcm_types.image_t import image_t
import threading
import json
import optparse

def compute_potential(obstacle_map, goal_map, dilation=30):
    selem = np.ones((dilation, dilation))
    mask = skimage.morphology.binary_dilation(obstacle_map, selem=selem).astype("bool")
    scene = npmask.array(goal_map, mask=mask)
    potential_map = skfmm.distance(scene)
    potential_map[mask] = np.inf
    return potential_map

def compute_gradient(potential_map, ij):
    ij = ij.reshape(-1)
    ij_min = None
    potential_min = np.inf
    for di in range(-2, 3):
        i = ij[0] + di
        if i >= 0 and i < potential_map.shape[0]:
            for dj in range(-2, 3):
                j = ij[1] + dj
                if j >= 0 and j < potential_map.shape[1] and (di != 0 or dj != 0):
                    if potential_map[i, j] < potential_min:
                        ij_min = np.array([i, j])
                        potential_min = potential_map[i, j]
    if ij_min is None:
        return np.array([np.nan, np.nan])
    else:
        return (ij_min - ij) / np.linalg.norm(ij_min - ij)

def compute_force(potential_map, scale, ij):
    ij = ij.reshape(-1)
    ij_min = None
    potential_min = np.inf
    for di in range(-1, 0, +1):
        i = ij[0] + di
        if i >= 0 and i < potential_map.shape[0]:
            for dj in range(-1, 0, +1):
                j = ij[1] + di
                if j >= 0 and j < potential_map.shape[1]:
                    if potential_map[i, j] < potential_min:
                        ij_min = np.array([i, j])
                        potential_min = potential_map[i, j]
    delta = (ij_min - ij) / (scale * np.linalg.norm(ij_min - ij) ** 2)
    return (potential_map[i, j] - potential_min) * delta

def potential_dynamics(inertia, damping, dt, velocity, force):
    return velocity + (dt / inertia) * (force - damping * velocity)

def decode_pose(msg_pose):
    pose_array = np.array(msg_pose.orientation + msg_pose.position)
    return msg_pose.timestamp, transformation.from_array(pose_array)

if __name__ == "__main__":
    # Parse command-line arguments
    parser = optparse.OptionParser()

    parser.add_option("-u", "--url", dest="url", help="Publish packets to LCMURL", metavar="LCMURL", default=None)
    parser.add_option("-c", "--config", dest="config", help="Read camera config from CONFIGFILE", metavar="CONFIGFILE")
    parser.add_option("-p", "--pose", dest="pose", help="Read pose from POSECHANNEL", metavar="POSECHANNEL", default="REALSENSE_POSE")
    parser.add_option("-t", "--pointcloud", dest="pointcloud", help="Read pointcloud from POINTCLOUDCHANNEL", metavar="POINTCLOUDCHANNEL", default="REALSENSE_POINTCLOUD")
    parser.add_option("-a", "--aruco", dest="aruco", help="Read aruco pose from ARUCOPOSECHANNEL", metavar="ARUCOPOSECHANNEL", default="ARUCO_POSE")
    parser.add_option("-v", "--visualize", dest="visualize", help="Show a visualization of integrated map", action="store_true")

    (options, args) = parser.parse_args()

    # Initialize the LCM node
    node = lcmutils.node(options.url)

    # Load the config file to read camera parameters, etc.
    with open(options.config) as f:
        config = json.load(f)

    # Construct an empty lattice to hold the occupancy grid of the environment
    delta = 0.03
    basis = delta * np.array([[1, 0, 0], [0, 1, 0]])
    normal = np.array([[0, 0, 1]])
    origin = np.array([-5, -5, 0])
    subspace = mapping.Subspace.from_components(basis, normal, origin)

    arr = np.zeros((int(10 / delta), int(10 / delta)), dtype="float")
    heightmap_lattice = mapping.Lattice(arr.copy(), subspace)
    slopemap_lattice = mapping.Lattice(arr.copy(), subspace)
    unsteppable_lattice = mapping.Lattice(arr.copy(), subspace)
    unpassable_lattice =mapping.Lattice(arr.copy(), subspace)
    print(arr.shape)

    max_slope = 45 # degrees
    passable_height = 0.3
    step_length = 0.2

    # Create a goal map to store where the goal point is
    goal_map = np.ones_like(arr, dtype="float")
    goal = np.array([ 3.97090387, -0.89732879, -0.19225973])
    goal_proj, _ = subspace.project(goal)
    goal_map[tuple(goal_proj.astype("int"))] = 0

    # Store the current pose for visualization purposes
    rgb = None
    pose = None
    aruco_pose = None

    arrow_length = int(15 * 0.02 / delta)
    circle_radius = int(7 * 0.02 / delta)
    cheetah_radius = 1.2
    cheetah_radius_px = int(cheetah_radius / delta)

    # Handle incoming pointclouds and pose over LCM by updating the occupancy grid with
    # the new points
    def input_handler(msg_pointcloud, msg_pose):
        global pose

        _, pose = decode_pose(msg_pose)
        points = np.array(msg_pointcloud.points).reshape(int(msg_pointcloud.n / 3), 3)
        points = pose * points
        camera = pose.t
        principal = pose * np.array([[1, 0, 0]]) - camera

        height_indices, heights = mapping.filter_indices(subspace, points, camera, principal, hthresh=-np.inf)
        indices = mapping.update_heightmap(heightmap_lattice, height_indices, heights)

        mapping.update_slopemap(heightmap_lattice, slopemap_lattice, indices)

        mapping.update_unsteppable(unsteppable_lattice, slopemap_lattice, delta, max_slope, indices)

        mapping.update_unpassable(unpassable_lattice, unsteppable_lattice, slopemap_lattice, passable_height, np.int(step_length/delta), indices)

        unsteppable_logical = unsteppable_lattice.arr.astype("bool") & (~unpassable_lattice.arr.astype("bool"))
        seen_logical = heightmap_lattice.arr.astype("bool") & ~(unpassable_lattice.arr.astype("bool") | unsteppable_logical.astype("bool"))

        camera_proj, _ = subspace.project(camera)
        # If visualization is turned on, show the occupancy grid, potential
        # function, and current position and orientation of the robot
        if options.visualize:
            unpassable_img = 255 * unpassable_lattice.arr.astype("uint8")
            unsteppable_img = 255 * unsteppable_logical.astype("uint8")
            seen_img = 255 * seen_logical.astype("uint8")
            img = np.dstack((unsteppable_img, seen_img, unpassable_img))

            principal_proj = subspace.project_vector(principal)
            principal_proj = principal_proj / np.linalg.norm(principal_proj)
               
            camera_origin = tuple(camera_proj[::-1].astype("int"))
            camera_end = tuple((camera_proj + arrow_length * principal_proj)[::-1].astype("int"))
            # cv2.arrowedLine(img, camera_origin, camera_end, (255, 255, 255), 1)

            if aruco_pose is not None:
                ix, _ = subspace.project(aruco_pose.t.reshape(1, -1))
                ix = tuple(ix.astype("int").reshape(-1)[::-1])
                cv2.circle(img, ix, 2, (255, 255, 255), -1)

            height, width = img.shape[:2]
            img = cv2.resize(img,(4*width, 4*height), interpolation = cv2.INTER_CUBIC)
            cv2.imshow("grid", img)

            if cv2.waitKey(1) == ord("q"):
                running = False
    
    def handle_aruco(msg_aruco):
        global aruco_pose
        _, aruco_pose_local = decode_pose(msg_aruco)
        if pose is not None:
            aruco_pose = pose * aruco_pose_local
    
    # Subscribe to the pointcloud and pose channels in a synchronized way (handled by
    # "input_handler")
    lcmutils.subscribe_sync_exact(node, [options.pointcloud, options.pose],
        [pointcloud_t, pose_t], input_handler, verbose=True)
    
    lcmutils.subscribe(node, options.aruco, pose_t, handle_aruco, verbose=True)
    
    # Constantly handle incoming LCM messages to update map
    while True:
        node.handle()

